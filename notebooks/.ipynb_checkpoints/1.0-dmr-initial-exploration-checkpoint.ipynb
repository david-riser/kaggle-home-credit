{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home Credit Default Risk\n",
    "In this notebook I explore the datasets provided for the home credit default risk kaggle challenge.  I will cover the following learning objectives here: \n",
    "- Working with structured data\n",
    "- Encoding of categorical variables \n",
    "- Handling missing values \n",
    "\n",
    "Some of this notebook follows the helpful kaggle kernel created by Will Koehrsen hosted [here](https://www.kaggle.com/willkoehrsen/start-here-a-gentle-introduction).  Our task is to create a model that predicts an applicants risk of default based on the provided datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/raw/application_test.csv\n",
      "../data/raw/HomeCredit_columns_description.csv\n",
      "../data/raw/POS_CASH_balance.csv\n",
      "../data/raw/credit_card_balance.csv\n",
      "../data/raw/installments_payments.csv\n",
      "../data/raw/application_train.csv\n",
      "../data/raw/bureau.csv\n",
      "../data/raw/previous_application.csv\n",
      "../data/raw/bureau_balance.csv\n",
      "../data/raw/sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "import glob \n",
    "path_to_data = '../data/raw/'\n",
    "\n",
    "for datafile in glob.glob(path_to_data + '*.csv'):\n",
    "    print(datafile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data \n",
    "The first thing I want to do is take a look at the structure of each dataset provided.  I will check the size of each dataset, the number of missing values, and the number of categorical features to be encoded or otherwise dealt with.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_structure(data):\n",
    "    \n",
    "    # Check shape\n",
    "    print('Dataset has shape (samples, features): ', data.shape)\n",
    "    \n",
    "    # Check missing values (percentage of total)\n",
    "    missing_values = data.isnull().sum() / len(data) * 100.0\n",
    "    missing_values.sort_values(ascending=False, inplace=True)\n",
    "    \n",
    "    print('\\nDataset missing values: ')\n",
    "    print(missing_values.head(12))\n",
    "    \n",
    "    # Check type of variables \n",
    "    print('\\nDataset value types: ')\n",
    "    print(data.dtypes.value_counts())\n",
    "    \n",
    "    # List categorical features and their number of unique values\n",
    "    print('\\nDataset categorical summary: ')\n",
    "    print(data.select_dtypes('object').apply(pd.Series.nunique, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "app_train = pd.read_csv(path_to_data + 'application_train.csv')\n",
    "installment_df = pd.read_csv(path_to_data + 'installments_payments.csv')\n",
    "credit_card_df = pd.read_csv(path_to_data + 'credit_card_balance.csv')\n",
    "bureau_df = pd.read_csv(path_to_data + 'bureau.csv')\n",
    "cash_df = pd.read_csv(path_to_data + 'POS_CASH_balance.csv')\n",
    "bureau_balance_df = pd.read_csv(path_to_data + 'bureau_balance.csv')\n",
    "prev_app_df = pd.read_csv(path_to_data + 'previous_application.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "description = pd.read_csv(path_to_data + 'HomeCredit_columns_description.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application Data \n",
    "This is the main dataset provided with the application, that contains 122 features/fields (one of those is the target).  It contains plenty of entries with missing data, and 16 features that are categorical in nature.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_structure(app_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installment Data \n",
    "This dataset provides information on previous home credit payments.  Each payment made or missed is a unique row.  The structure of this dataset is simple, containing very few missing values and no categorical variables.  It contains 8 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_structure(installment_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credit Card Data\n",
    "Information on credit cards previously held with home credit.  Contains 23 features, some missing data, and one categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_structure(credit_card_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bureau Data \n",
    "Information about the clients credit standings with other financial institutions.  This dataset contains 17 features, a fair amount of missing data in 4-5 of the fields, and contains three categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_structure(bureau_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cash Dataset \n",
    "Point of sale cash and loans information.  This dataset contains eight features, one of which is categorical, and almost no missing entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_structure(cash_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bureau Balance Data \n",
    "This dataset details the payment information from the bureau.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_structure(bureau_balance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous Application Data \n",
    "This dataset contains the applicants previous applications for home credit.  It seems to be the second largest, after the applcation, and has 16 categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_structure(prev_app_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Data \n",
    "In the following section, the data are aggregated by the applicant identification number `SK_ID_CURR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installment_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in installment_df.columns:\n",
    "    print(c, description[description.Row == c].Description.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add features to installment dataset here.\n",
    "installment_df['PAYMENT_DIFF'] = installment_df.AMT_PAYMENT - installment_df.AMT_INSTALMENT\n",
    "installment_df['PAYMENT_PERC'] = installment_df.AMT_PAYMENT / installment_df.AMT_INSTALMENT\n",
    "installment_df['DPD'] = installment_df.DAYS_INSTALMENT - installment_df.DAYS_ENTRY_PAYMENT\n",
    "\n",
    "# Define aggregation methods for float/int cols\n",
    "aggregations = {\n",
    "    'NUM_INSTALMENT_VERSION': ['mean', 'min', 'max'],\n",
    "    'NUM_INSTALMENT_NUMBER': ['mean', 'min', 'max'],\n",
    "    'DAYS_INSTALMENT': ['mean', 'min', 'max'],\n",
    "    'DAYS_ENTRY_PAYMENT': ['mean', 'min', 'max'],\n",
    "    'AMT_INSTALMENT': ['mean', 'min', 'max'],\n",
    "    'AMT_PAYMENT': ['mean', 'min', 'max'],\n",
    "    'PAYMENT_DIFF': ['min', 'max', 'mean'],\n",
    "    'PAYMENT_PERC': ['min', 'max', 'mean'],\n",
    "    'DPD': ['min', 'max', 'mean']\n",
    "               }\n",
    "\n",
    "install_agg = installment_df.groupby('SK_ID_CURR').aggregate(aggregations)\n",
    "\n",
    "colname = lambda x, y: 'INSTALL_' + x + '_' + y.upper() \n",
    "new_cols = [colname(c[0],c[1]) for c in list(install_agg.columns)]\n",
    "install_agg.columns = new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for c in credit_card_df.columns:\n",
    "    print(c, description[description.Row == c].Description.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [credit_card_df.columns[i] for i, c in enumerate(credit_card_df.dtypes) if c == 'object']\n",
    "print('Categoricals: ', cat_cols)\n",
    "\n",
    "credit_card_df['BALANCE_PERC'] =  credit_card_df.AMT_BALANCE / credit_card_df.AMT_CREDIT_LIMIT_ACTUAL\n",
    "\n",
    "# Map the unique strings to unique integers.\n",
    "for cat in cat_cols: \n",
    "    encoder = LabelEncoder()\n",
    "    credit_card_df[cat] = encoder.fit_transform(credit_card_df[cat])\n",
    "    \n",
    "# Add features that make sense here.    \n",
    "#aggregations = {\n",
    "#    'AMT_BALANCE': ['min', 'mean', 'max'],\n",
    "#    'BALANCE_PERC': ['min', 'max', 'mean']\n",
    "#}\n",
    "\n",
    "# Do more custom modification.\n",
    "#credit_card_agg = credit_card_df.groupby('SK_ID_CURR').aggregate(aggregations)\n",
    "\n",
    "# Do general aggregations.\n",
    "credit_card_agg = credit_card_df.groupby('SK_ID_CURR').aggregate(['min', 'max', 'sum', 'var', 'mean'])\n",
    "\n",
    "colname = lambda x, y: 'CC_' + x + '_' + y.upper() \n",
    "new_cols = [colname(c[0],c[1]) for c in list(credit_card_agg.columns)]\n",
    "credit_card_agg.columns = new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_card_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in bureau_df.columns:\n",
    "    print(c, description[description.Row == c].Description.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [bureau_df.columns[i] for i, c in enumerate(bureau_df.dtypes) if c == 'object']\n",
    "print('Categoricals: ', cat_cols)\n",
    "\n",
    "# Change the strings to integers.\n",
    "for cat in cat_cols: \n",
    "    encoder = LabelEncoder()\n",
    "    bureau_df[cat] = encoder.fit_transform(bureau_df[cat])\n",
    "    \n",
    "# Add features that make sense here.    \n",
    "#aggregations = {\n",
    "#    'DAYS_CREDIT': ['min', 'mean', 'max']\n",
    "#}\n",
    "\n",
    "bureau_agg = bureau_df.groupby('SK_ID_CURR').aggregate(['min', 'max', 'sum', 'mean', 'var'])\n",
    "colname = lambda x, y: 'CC_' + x + '_' + y.upper() \n",
    "new_cols = [colname(c[0],c[1]) for c in list(bureau_agg.columns)]\n",
    "bureau_agg.columns = new_cols\n",
    "\n",
    "print('Bureau shape: ', bureau_df.shape)\n",
    "print('Bureau (agg) shape: ', bureau_agg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cash_df.columns:\n",
    "    print(c, description[description.Row == c].Description.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [cash_df.columns[i] for i, c in enumerate(cash_df.dtypes) if c == 'object']\n",
    "print('Categoricals: ', cat_cols)\n",
    "\n",
    "# Change the strings to integers.\n",
    "for cat in cat_cols: \n",
    "    encoder = LabelEncoder()\n",
    "    cash_df[cat] = encoder.fit_transform(cash_df[cat])\n",
    "    \n",
    "# Add features that make sense here.    \n",
    "#aggregations = {\n",
    "#    'SK_DPD': ['min', 'mean', 'max']\n",
    "#}\n",
    "\n",
    "cash_agg = cash_df.groupby('SK_ID_CURR').aggregate(['min', 'max', 'sum', 'var', 'mean'])\n",
    "colname = lambda x, y: 'CC_' + x + '_' + y.upper() \n",
    "new_cols = [colname(c[0],c[1]) for c in list(cash_agg.columns)]\n",
    "cash_agg.columns = new_cols\n",
    "\n",
    "print('Cash shape: ', cash_df.shape)\n",
    "print('Cash (agg) shape: ', cash_agg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for c in bureau_balance_df.columns:\n",
    "    print(c, description[description.Row == c].Description.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [bureau_balance_df.columns[i] for i, c in enumerate(bureau_balance_df.dtypes) if c == 'object']\n",
    "print('Categoricals: ', cat_cols)\n",
    "\n",
    "# Change the strings to integers.\n",
    "for cat in cat_cols: \n",
    "    encoder = LabelEncoder()\n",
    "    bureau_balance_df[cat] = encoder.fit_transform(bureau_balance_df[cat])\n",
    "    \n",
    "# Add features that make sense here.    \n",
    "aggregations = {\n",
    "    'SK_DPD': ['min', 'mean', 'max']\n",
    "}\n",
    "\n",
    "bureau_balance_agg = cash_df.groupby('SK_ID_CURR').aggregate(aggregations)\n",
    "colname = lambda x, y: 'BB_' + x + '_' + y.upper() \n",
    "new_cols = [colname(c[0],c[1]) for c in list(bureau_agg.columns)]\n",
    "bureau_balance_agg.columns = new_cols\n",
    "\n",
    "print('Bureau balance shape: ', bureau_balance_df.shape)\n",
    "print('Bureau balance (agg) shape: ', bureau_balance_agg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in prev_app_df.columns:\n",
    "    print(c, description[description.Row == c].Description.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [prev_app_df.columns[i] for i, c in enumerate(prev_app_df.dtypes) if c == 'object']\n",
    "print('Categoricals: ', cat_cols)\n",
    "\n",
    "# Change the strings to integers.\n",
    "for cat in cat_cols: \n",
    "    encoder = LabelEncoder()\n",
    "    prev_app_df[cat] = encoder.fit_transform(prev_app_df[cat])\n",
    "    \n",
    "# Add features that make sense here.    \n",
    "aggregations = {\n",
    "    'CNT_PAYMENT': ['min', 'mean', 'max']\n",
    "}\n",
    "\n",
    "prev_app_agg = prev_app_df.groupby('SK_ID_CURR').aggregate(aggregations)\n",
    "colname = lambda x, y: 'BB_' + x + '_' + y.upper() \n",
    "new_cols = [colname(c[0],c[1]) for c in list(prev_app_agg.columns)]\n",
    "prev_app_agg.columns = new_cols\n",
    "\n",
    "print('Previous application shape: ', prev_app_df.shape)\n",
    "print('Previous application (agg) shape: ', prev_app_agg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
