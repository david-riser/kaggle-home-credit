{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removal of Null Values \n",
    "The training and testing data produced by `src/features/1.X-features.py` contains many missing values.  In training tree based models such as `xgboost` and `lightgbm` this causes no problems, however the models in the `sklearn` module expect to operate on numpy arrays that contain no null values (missing or infinite).  \n",
    "\n",
    "This problem can be fixed in several ways.  The methods I have applied have failed to properly clean the data, this notebook is a hands-on exploration into why this happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data V1.1\n",
    "The second version of the aggregated data is currently the most advanced.  I am now loading both training and testing in dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_train = '../data/processed/1.1-features-train.csv'\n",
    "path_to_test  = '../data/processed/1.1-features-test.csv'\n",
    "sample_size = None\n",
    "\n",
    "train = pd.read_csv(path_to_train, compression='gzip', nrows=sample_size)\n",
    "test  = pd.read_csv(path_to_test, compression='gzip', nrows=sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training shape:', (307511, 542))\n",
      "('Testing shape:', (48744, 541))\n"
     ]
    }
   ],
   "source": [
    "print('Training shape:', train.shape)\n",
    "print('Testing shape:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREV_RATE_INTEREST_PRIVILEGED_VAR           307337\n",
      "PREV_RATE_INTEREST_PRIMARY_VAR              307337\n",
      "BUREAU_CREDIT_RATIO_VAR                     306956\n",
      "PREV_DAYS_FIRST_DRAWING_MAX                 305019\n",
      "PREV_RATE_INTEREST_PRIVILEGED_MEAN          302902\n",
      "PREV_RATE_INTEREST_PRIVILEGED_MAX           302902\n",
      "PREV_RATE_INTEREST_PRIVILEGED_MIN           302902\n",
      "PREV_RATE_INTEREST_PRIMARY_MEAN             302902\n",
      "PREV_RATE_INTEREST_PRIMARY_MAX              302902\n",
      "PREV_RATE_INTEREST_PRIMARY_MIN              302902\n",
      "BUREAU_OVERDUE_RATIO_VAR                    296636\n",
      "BUREAU_OVERDUE_RATIO_MAX                    257091\n",
      "BUREAU_OVERDUE_RATIO_MEAN                   257091\n",
      "BUREAU_OVERDUE_RATIO_MIN                    257091\n",
      "CREDIT_CARD_AMT_ATM_RATIO_VAR               254945\n",
      "CREDIT_CARD_AMT_POS_RATIO_VAR               254944\n",
      "CREDIT_CARD_AMT_OTHER_RATIO_VAR             254944\n",
      "PREV_DAYS_FIRST_DRAWING_MIN                 254159\n",
      "PREV_DAYS_FIRST_DRAWING_MEAN                254159\n",
      "CREDIT_CARD_AMT_ATM_RATIO_MEAN              247875\n",
      "CREDIT_CARD_AMT_ATM_RATIO_MAX               247875\n",
      "CREDIT_CARD_AMT_POS_RATIO_MIN               247875\n",
      "CREDIT_CARD_AMT_POS_RATIO_MAX               247875\n",
      "CREDIT_CARD_AMT_POS_RATIO_MEAN              247875\n",
      "CREDIT_CARD_AMT_OTHER_RATIO_MIN             247875\n",
      "CREDIT_CARD_AMT_OTHER_RATIO_MAX             247875\n",
      "CREDIT_CARD_AMT_OTHER_RATIO_MEAN            247875\n",
      "CREDIT_CARD_AMT_ATM_RATIO_MIN               247875\n",
      "CREDIT_CARD_AMT_PAYMENT_CURRENT_VAR         246892\n",
      "CREDIT_CARD_CNT_DRAWINGS_POS_CURRENT_VAR    246818\n",
      "                                             ...  \n",
      "WALLSMATERIAL_MODE                               0\n",
      "WEEKDAY_APPR_PROCESS_START                       0\n",
      "test                                             0\n",
      "DAYS_EMPLOYED_PERCENT                            0\n",
      "CREDIT_INCOME_PERCENT                            0\n",
      "LIVE_REGION_NOT_WORK_REGION                      0\n",
      "HOUSETYPE_MODE                                   0\n",
      "FLAG_DOCUMENT_17                                 0\n",
      "FLAG_DOCUMENT_7                                  0\n",
      "FLAG_DOCUMENT_18                                 0\n",
      "FLAG_DOCUMENT_19                                 0\n",
      "FLAG_DOCUMENT_2                                  0\n",
      "FLAG_DOCUMENT_20                                 0\n",
      "FLAG_DOCUMENT_21                                 0\n",
      "FLAG_DOCUMENT_3                                  0\n",
      "FLAG_DOCUMENT_4                                  0\n",
      "FLAG_DOCUMENT_5                                  0\n",
      "FLAG_DOCUMENT_6                                  0\n",
      "FLAG_DOCUMENT_8                                  0\n",
      "HOUR_APPR_PROCESS_START                          0\n",
      "FLAG_DOCUMENT_9                                  0\n",
      "FLAG_EMAIL                                       0\n",
      "FLAG_EMP_PHONE                                   0\n",
      "FLAG_MOBIL                                       0\n",
      "FLAG_OWN_CAR                                     0\n",
      "FLAG_OWN_REALTY                                  0\n",
      "FLAG_PHONE                                       0\n",
      "FLAG_WORK_PHONE                                  0\n",
      "FONDKAPREMONT_MODE                               0\n",
      "Unnamed: 0                                       0\n",
      "Length: 542, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREV_RATE_INTEREST_PRIVILEGED_VAR           48700\n",
      "PREV_RATE_INTEREST_PRIMARY_VAR              48700\n",
      "BUREAU_CREDIT_RATIO_VAR                     48614\n",
      "PREV_DAYS_FIRST_DRAWING_MAX                 48598\n",
      "PREV_RATE_INTEREST_PRIMARY_MAX              47632\n",
      "PREV_RATE_INTEREST_PRIMARY_MIN              47632\n",
      "PREV_RATE_INTEREST_PRIVILEGED_MEAN          47632\n",
      "PREV_RATE_INTEREST_PRIMARY_MEAN             47632\n",
      "PREV_RATE_INTEREST_PRIVILEGED_MAX           47632\n",
      "PREV_RATE_INTEREST_PRIVILEGED_MIN           47632\n",
      "BUREAU_OVERDUE_RATIO_VAR                    47409\n",
      "BUREAU_OVERDUE_RATIO_MEAN                   40898\n",
      "BUREAU_OVERDUE_RATIO_MAX                    40898\n",
      "BUREAU_OVERDUE_RATIO_MIN                    40898\n",
      "PREV_DAYS_FIRST_DRAWING_MEAN                39593\n",
      "PREV_DAYS_FIRST_DRAWING_MIN                 39593\n",
      "CREDIT_CARD_AMT_OTHER_RATIO_VAR             39415\n",
      "CREDIT_CARD_AMT_POS_RATIO_VAR               39415\n",
      "CREDIT_CARD_AMT_ATM_RATIO_VAR               39415\n",
      "CREDIT_CARD_AMT_OTHER_RATIO_MEAN            38115\n",
      "CREDIT_CARD_AMT_OTHER_RATIO_MAX             38115\n",
      "CREDIT_CARD_AMT_OTHER_RATIO_MIN             38115\n",
      "CREDIT_CARD_AMT_POS_RATIO_MIN               38115\n",
      "CREDIT_CARD_AMT_POS_RATIO_MAX               38115\n",
      "CREDIT_CARD_AMT_POS_RATIO_MEAN              38115\n",
      "CREDIT_CARD_AMT_ATM_RATIO_MEAN              38115\n",
      "CREDIT_CARD_AMT_ATM_RATIO_MIN               38115\n",
      "CREDIT_CARD_AMT_ATM_RATIO_MAX               38115\n",
      "CREDIT_CARD_AMT_PAYMENT_CURRENT_VAR         37761\n",
      "CREDIT_CARD_AMT_DRAWINGS_ATM_CURRENT_VAR    37745\n",
      "                                            ...  \n",
      "SK_ID_CURR                                      0\n",
      "WALLSMATERIAL_MODE                              0\n",
      "WEEKDAY_APPR_PROCESS_START                      0\n",
      "CREDIT_GOODS_RATIO                              0\n",
      "CREDIT_INCOME_PERCENT                           0\n",
      "LIVE_REGION_NOT_WORK_REGION                     0\n",
      "HOUSETYPE_MODE                                  0\n",
      "FLAG_DOCUMENT_17                                0\n",
      "FLAG_DOCUMENT_7                                 0\n",
      "FLAG_DOCUMENT_18                                0\n",
      "FLAG_DOCUMENT_19                                0\n",
      "FLAG_DOCUMENT_2                                 0\n",
      "FLAG_DOCUMENT_20                                0\n",
      "FLAG_DOCUMENT_21                                0\n",
      "FLAG_DOCUMENT_3                                 0\n",
      "FLAG_DOCUMENT_4                                 0\n",
      "FLAG_DOCUMENT_5                                 0\n",
      "FLAG_DOCUMENT_6                                 0\n",
      "FLAG_DOCUMENT_8                                 0\n",
      "HOUR_APPR_PROCESS_START                         0\n",
      "FLAG_DOCUMENT_9                                 0\n",
      "DAYS_EMPLOYED_PERCENT                           0\n",
      "FLAG_EMP_PHONE                                  0\n",
      "FLAG_MOBIL                                      0\n",
      "FLAG_OWN_CAR                                    0\n",
      "FLAG_OWN_REALTY                                 0\n",
      "FLAG_PHONE                                      0\n",
      "FLAG_WORK_PHONE                                 0\n",
      "FONDKAPREMONT_MODE                              0\n",
      "Unnamed: 0                                      0\n",
      "Length: 541, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(test.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear from looking at the number of entries in training and testing data and looking at the top missing values that there are entire columns which contain no information at all.  These columns should be removed before saving the data files (a change which I will implement in `1.2-features.py` after fixing all issues).\n",
    "\n",
    "Let's start by dropping those columns from testing and training that have a very large percentage of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "percentage_threshold = 0.9\n",
    "\n",
    "train_missing = train.isnull().sum().sort_values(ascending=False) / len(train)\n",
    "test_missing = test.isnull().sum().sort_values(ascending=False) / len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_train_cols = [col for col in train_missing.index if train_missing[col] > percentage_threshold]\n",
    "drop_test_cols = [col for col in test_missing.index if test_missing[col] > percentage_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PREV_RATE_INTEREST_PRIVILEGED_VAR', 'PREV_RATE_INTEREST_PRIMARY_VAR', 'BUREAU_CREDIT_RATIO_VAR', 'PREV_DAYS_FIRST_DRAWING_MAX', 'PREV_RATE_INTEREST_PRIVILEGED_MEAN', 'PREV_RATE_INTEREST_PRIVILEGED_MAX', 'PREV_RATE_INTEREST_PRIVILEGED_MIN', 'PREV_RATE_INTEREST_PRIMARY_MEAN', 'PREV_RATE_INTEREST_PRIMARY_MAX', 'PREV_RATE_INTEREST_PRIMARY_MIN', 'BUREAU_OVERDUE_RATIO_VAR']\n"
     ]
    }
   ],
   "source": [
    "print(drop_train_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PREV_RATE_INTEREST_PRIVILEGED_VAR', 'PREV_RATE_INTEREST_PRIMARY_VAR', 'BUREAU_CREDIT_RATIO_VAR', 'PREV_DAYS_FIRST_DRAWING_MAX', 'PREV_RATE_INTEREST_PRIMARY_MAX', 'PREV_RATE_INTEREST_PRIMARY_MIN', 'PREV_RATE_INTEREST_PRIVILEGED_MEAN', 'PREV_RATE_INTEREST_PRIMARY_MEAN', 'PREV_RATE_INTEREST_PRIVILEGED_MAX', 'PREV_RATE_INTEREST_PRIVILEGED_MIN', 'BUREAU_OVERDUE_RATIO_VAR']\n"
     ]
    }
   ],
   "source": [
    "print(drop_test_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it's evident that the method used in `1.1-features.py` leaves an empty TARGET column in the testing dataset.  That should be dropped before saving the features.  I will remove that now and update it in the next version.  \n",
    "\n",
    "Next, all columns from training and testing needed to be dropped in both that have values over threshold in either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "labels ['TARGET'] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-9c7be9264033>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TARGET'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrop_test_cols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TARGET'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   2528\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2530\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   2560\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2562\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2563\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2564\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/core/indexes/base.pyc\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   3742\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3743\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[0;32m-> 3744\u001b[0;31m                                  labels[mask])\n\u001b[0m\u001b[1;32m   3745\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3746\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: labels ['TARGET'] not contained in axis"
     ]
    }
   ],
   "source": [
    "test.drop(columns=['TARGET'], inplace=True)\n",
    "drop_test_cols.remove('TARGET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train shape:', (307511, 531))\n",
      "('Test shape:', (48744, 530))\n"
     ]
    }
   ],
   "source": [
    "drop_cols = drop_train_cols\n",
    "\n",
    "for col in drop_test_cols:\n",
    "    if col not in drop_cols:\n",
    "        drop_cols.append(col)\n",
    "        \n",
    "train.drop(columns=drop_cols, inplace=True)\n",
    "test.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "print('Train shape:', train.shape)\n",
    "print('Test shape:', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple filling of nulls \n",
    "The first test I would like to perform is simply filling the null values with 0.  This is simple in pandas.  I can then repeat the cells from above to check null content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_filled = train.fillna(0)\n",
    "test_filled = test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREV_COUNT                                   0\n",
      "CREDIT_CARD_MONTHS_BALANCE_MAX               0\n",
      "INSTALL_DAYS_BEFORE_DUE_MIN                  0\n",
      "INSTALL_DAYS_BEFORE_DUE_MAX                  0\n",
      "INSTALL_DAYS_BEFORE_DUE_MEAN                 0\n",
      "INSTALL_DAYS_BEFORE_DUE_VAR                  0\n",
      "INSTALL_LATE_PAYMENT_MIN                     0\n",
      "INSTALL_LATE_PAYMENT_MAX                     0\n",
      "INSTALL_LATE_PAYMENT_MEAN                    0\n",
      "INSTALL_LATE_PAYMENT_VAR                     0\n",
      "INSTALL_COUNT                                0\n",
      "CREDIT_CARD_SK_ID_PREV_MIN                   0\n",
      "CREDIT_CARD_SK_ID_PREV_MAX                   0\n",
      "CREDIT_CARD_SK_ID_PREV_MEAN                  0\n",
      "CREDIT_CARD_SK_ID_PREV_VAR                   0\n",
      "CREDIT_CARD_MONTHS_BALANCE_MIN               0\n",
      "CREDIT_CARD_MONTHS_BALANCE_MEAN              0\n",
      "INSTALL_SK_ID_PREV_MAX                       0\n",
      "CREDIT_CARD_MONTHS_BALANCE_VAR               0\n",
      "CREDIT_CARD_AMT_BALANCE_MIN                  0\n",
      "CREDIT_CARD_AMT_BALANCE_MAX                  0\n",
      "CREDIT_CARD_AMT_BALANCE_MEAN                 0\n",
      "CREDIT_CARD_AMT_BALANCE_VAR                  0\n",
      "CREDIT_CARD_AMT_CREDIT_LIMIT_ACTUAL_MIN      0\n",
      "CREDIT_CARD_AMT_CREDIT_LIMIT_ACTUAL_MAX      0\n",
      "CREDIT_CARD_AMT_CREDIT_LIMIT_ACTUAL_MEAN     0\n",
      "CREDIT_CARD_AMT_CREDIT_LIMIT_ACTUAL_VAR      0\n",
      "CREDIT_CARD_AMT_DRAWINGS_ATM_CURRENT_MIN     0\n",
      "CREDIT_CARD_AMT_DRAWINGS_ATM_CURRENT_MAX     0\n",
      "CREDIT_CARD_AMT_DRAWINGS_ATM_CURRENT_MEAN    0\n",
      "                                            ..\n",
      "BUREAU_AMT_CREDIT_SUM_LIMIT_MAX              0\n",
      "BUREAU_AMT_CREDIT_SUM_LIMIT_MEAN             0\n",
      "BUREAU_AMT_CREDIT_SUM_LIMIT_VAR              0\n",
      "BUREAU_AMT_CREDIT_SUM_OVERDUE_MIN            0\n",
      "BUREAU_AMT_CREDIT_SUM_OVERDUE_MAX            0\n",
      "BUREAU_AMT_CREDIT_SUM_OVERDUE_MEAN           0\n",
      "BUREAU_AMT_CREDIT_SUM_OVERDUE_VAR            0\n",
      "BUREAU_CREDIT_TYPE_MIN                       0\n",
      "BUREAU_CREDIT_TYPE_MAX                       0\n",
      "BUREAU_CREDIT_TYPE_MEAN                      0\n",
      "BUREAU_CREDIT_TYPE_VAR                       0\n",
      "BUREAU_DAYS_CREDIT_UPDATE_MIN                0\n",
      "BUREAU_DAYS_CREDIT_UPDATE_MAX                0\n",
      "BUREAU_DAYS_CREDIT_UPDATE_MEAN               0\n",
      "BUREAU_DAYS_CREDIT_UPDATE_VAR                0\n",
      "BUREAU_AMT_ANNUITY_MIN                       0\n",
      "BUREAU_AMT_ANNUITY_MAX                       0\n",
      "BUREAU_AMT_ANNUITY_MEAN                      0\n",
      "BUREAU_AMT_ANNUITY_VAR                       0\n",
      "BUREAU_CREDIT_RATIO_MIN                      0\n",
      "BUREAU_CREDIT_RATIO_MAX                      0\n",
      "BUREAU_CREDIT_RATIO_MEAN                     0\n",
      "BUREAU_OVERDUE_RATIO_MIN                     0\n",
      "BUREAU_OVERDUE_RATIO_MAX                     0\n",
      "BUREAU_OVERDUE_RATIO_MEAN                    0\n",
      "CASH_SK_ID_PREV_MIN                          0\n",
      "CASH_SK_ID_PREV_MAX                          0\n",
      "CASH_SK_ID_PREV_MEAN                         0\n",
      "CASH_SK_ID_PREV_VAR                          0\n",
      "Unnamed: 0                                   0\n",
      "Length: 531, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_filled.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREV_COUNT                                   0\n",
      "CREDIT_CARD_MONTHS_BALANCE_MEAN              0\n",
      "INSTALL_DAYS_BEFORE_DUE_MAX                  0\n",
      "INSTALL_DAYS_BEFORE_DUE_MEAN                 0\n",
      "INSTALL_DAYS_BEFORE_DUE_VAR                  0\n",
      "INSTALL_LATE_PAYMENT_MIN                     0\n",
      "INSTALL_LATE_PAYMENT_MAX                     0\n",
      "INSTALL_LATE_PAYMENT_MEAN                    0\n",
      "INSTALL_LATE_PAYMENT_VAR                     0\n",
      "INSTALL_COUNT                                0\n",
      "CREDIT_CARD_SK_ID_PREV_MIN                   0\n",
      "CREDIT_CARD_SK_ID_PREV_MAX                   0\n",
      "CREDIT_CARD_SK_ID_PREV_MEAN                  0\n",
      "CREDIT_CARD_SK_ID_PREV_VAR                   0\n",
      "CREDIT_CARD_MONTHS_BALANCE_MIN               0\n",
      "CREDIT_CARD_MONTHS_BALANCE_MAX               0\n",
      "CREDIT_CARD_MONTHS_BALANCE_VAR               0\n",
      "INSTALL_SK_ID_PREV_MEAN                      0\n",
      "CREDIT_CARD_AMT_BALANCE_MIN                  0\n",
      "CREDIT_CARD_AMT_BALANCE_MAX                  0\n",
      "CREDIT_CARD_AMT_BALANCE_MEAN                 0\n",
      "CREDIT_CARD_AMT_BALANCE_VAR                  0\n",
      "CREDIT_CARD_AMT_CREDIT_LIMIT_ACTUAL_MIN      0\n",
      "CREDIT_CARD_AMT_CREDIT_LIMIT_ACTUAL_MAX      0\n",
      "CREDIT_CARD_AMT_CREDIT_LIMIT_ACTUAL_MEAN     0\n",
      "CREDIT_CARD_AMT_CREDIT_LIMIT_ACTUAL_VAR      0\n",
      "CREDIT_CARD_AMT_DRAWINGS_ATM_CURRENT_MIN     0\n",
      "CREDIT_CARD_AMT_DRAWINGS_ATM_CURRENT_MAX     0\n",
      "CREDIT_CARD_AMT_DRAWINGS_ATM_CURRENT_MEAN    0\n",
      "CREDIT_CARD_AMT_DRAWINGS_ATM_CURRENT_VAR     0\n",
      "                                            ..\n",
      "BUREAU_AMT_CREDIT_SUM_LIMIT_MAX              0\n",
      "BUREAU_AMT_CREDIT_SUM_LIMIT_MEAN             0\n",
      "BUREAU_AMT_CREDIT_SUM_LIMIT_VAR              0\n",
      "BUREAU_AMT_CREDIT_SUM_OVERDUE_MIN            0\n",
      "BUREAU_AMT_CREDIT_SUM_OVERDUE_MAX            0\n",
      "BUREAU_AMT_CREDIT_SUM_OVERDUE_MEAN           0\n",
      "BUREAU_AMT_CREDIT_SUM_OVERDUE_VAR            0\n",
      "BUREAU_CREDIT_TYPE_MIN                       0\n",
      "BUREAU_CREDIT_TYPE_MAX                       0\n",
      "BUREAU_CREDIT_TYPE_MEAN                      0\n",
      "BUREAU_CREDIT_TYPE_VAR                       0\n",
      "BUREAU_DAYS_CREDIT_UPDATE_MIN                0\n",
      "BUREAU_DAYS_CREDIT_UPDATE_MAX                0\n",
      "BUREAU_DAYS_CREDIT_UPDATE_MEAN               0\n",
      "BUREAU_DAYS_CREDIT_UPDATE_VAR                0\n",
      "BUREAU_AMT_ANNUITY_MIN                       0\n",
      "BUREAU_AMT_ANNUITY_MAX                       0\n",
      "BUREAU_AMT_ANNUITY_MEAN                      0\n",
      "BUREAU_AMT_ANNUITY_VAR                       0\n",
      "BUREAU_CREDIT_RATIO_MIN                      0\n",
      "BUREAU_CREDIT_RATIO_MAX                      0\n",
      "BUREAU_CREDIT_RATIO_MEAN                     0\n",
      "BUREAU_OVERDUE_RATIO_MIN                     0\n",
      "BUREAU_OVERDUE_RATIO_MAX                     0\n",
      "BUREAU_OVERDUE_RATIO_MEAN                    0\n",
      "CASH_SK_ID_PREV_MIN                          0\n",
      "CASH_SK_ID_PREV_MAX                          0\n",
      "CASH_SK_ID_PREV_MEAN                         0\n",
      "CASH_SK_ID_PREV_VAR                          0\n",
      "Unnamed: 0                                   0\n",
      "Length: 530, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(test_filled.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify with model\n",
    "Visually the data now looks like it should work in an `sklearn` model.  Let's setup a simple model and train to verify this.  I won't be using proper training validation techniques, as I only care about the functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/numpy/core/_methods.py:32: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-f376dece795c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_filled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/linear_model/logistic.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=np.float64,\n\u001b[0;32m-> 1173\u001b[0;31m                          order=\"C\")\n\u001b[0m\u001b[1;32m   1174\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    520\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "y_train = train_filled['TARGET'].values \n",
    "train_filled.drop(columns=['TARGET'], inplace=True)\n",
    "\n",
    "x_train = train_filled.values\n",
    "\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Failure\n",
    "Even though pandas appears to show no nulls, numpy verifies that the array is not yet finite.  Let's try to identify where those values are and print them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isfinite(x_train).all(), np.isfinite(y_train).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finite_mask = np.isfinite(x_train)\n",
    "bad_idx = np.where(finite_mask == False)\n",
    "print(bad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train[bad_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly there are still infinite values.  Let's try to find those in the dataframe as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bad_df_idx = np.where(train_filled.values == np.inf)\n",
    "print(train_filled.iloc[bad_df_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed they exist in the dataframe as well, evidently the fillna call doesn't handle infinities.  Let's try directly replacing these in the filled dataframe. What's more, this looks like the result of feature engineering where the customer had zero entries and could likely be removed directly instead of handled later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "train_filled.replace(np.inf, 0, inplace=True)\n",
    "test_filled.replace(np.inf, 0, inplace=True)\n",
    "train_filled.replace(-np.inf, 0, inplace=True)\n",
    "test_filled.replace(-np.inf, 0, inplace=True)\n",
    "\n",
    "bad_df_idx = np.where(train_filled.values == np.inf)\n",
    "print(train_filled.iloc[bad_df_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible fix? \n",
    "If these results are true, the model should be able to train now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "x_train = train_filled.values\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/linear_model/base.py:352: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr.predict_proba(test_filled.values)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.46233868, 0.3478548 , 0.31795753, ..., 0.08413099, 0.01572545,\n",
       "       0.04293689])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "This notebook has explored the existing problems with null and infinite values in the features datasets.  Additionally, the misunderstanding that I had about how fillna works.  To conclude, the following changes need to be added to the version `1.2-features.py`:\n",
    "* Drop target column from testing dataset \n",
    "* Drop columns that contain no information before saving\n",
    "* Consider checking the features BUREAU_CREDIT_RATIO_MEAN and adding protection for infinite cases.\n",
    "Additionally, the problem can be simply fixed by filling na values first, and then replacing np.inf and -np.inf with the value of your choice. \n",
    "\n",
    "Before quitting, let's see if the Imputer from `sklearn.preprocessing` would solve the problem for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = list(train.columns)\n",
    "features.remove('TARGET')\n",
    "\n",
    "imp = Imputer()\n",
    "train_imp = imp.fit_transform(train[features])\n",
    "test_imp = imp.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finite_mask = np.isfinite(train_imp)\n",
    "bad_idx = np.where(finite_mask == False)\n",
    "print(bad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "x_train = train_imp\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = lr.predict_proba(test_imp)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This appears to directly solve the problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
